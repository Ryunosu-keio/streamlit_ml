import shap
from lime.lime_tabular import LimeTabularExplainer
import streamlit.components.v1 as components
import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


def explain_shap(clf_model, X_train: pd.DataFrame, X_test: pd.DataFrame, task_type: str, ml_type: str):
    """
    Display SHAP summary and waterfall plots in Streamlit.
    """
    st.markdown("## SHAP ã«ã‚ˆã‚‹èª¬æ˜")
    
    # Explainer ã®é¸æŠ
    if ml_type in ("æ±ºå®šæœ¨", "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ"):
        explainer = shap.TreeExplainer(clf_model)
    else:
        explainer = shap.KernelExplainer(
            clf_model.predict_proba if task_type == "åˆ†é¡" else clf_model.predict,
            X_train.sample(min(50, len(X_train)), random_state=0)
        )

    # ã‚µãƒ³ãƒ—ãƒ«ã‚’çµã£ã¦è¨ˆç®—
    sample_idx = X_test.sample(min(50, len(X_test)), random_state=0).index
    sample_X = X_test.loc[sample_idx]
    shap_values = explainer.shap_values(sample_X)

    # Global summary plot
    st.text("SHAP summary plot (global)")
    
    # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    fig = plt.figure(figsize=(8, 6))
    shap.summary_plot(shap_values, sample_X, show=False)
    st.pyplot(fig)

    fig2 = plt.figure(figsize=(8, 6))
    st.text("SHAP summary plot (bar)")
    shap.summary_plot(shap_values, sample_X, plot_type="bar", show=False)
    st.pyplot(fig2)
    
    

    # Local explanation: waterfall plot
    idx = st.slider("ğŸ” SHAP waterfall plot ã§è¦‹ã‚‹ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹", 0, len(X_test)-1, 0)
    st.text(f"Index={idx} ã®ãƒ­ãƒ¼ã‚«ãƒ«èª¬æ˜ (waterfall plot)")
    sv_local = explainer.shap_values(X_test.iloc[idx:idx+1])

    # å¤šæ¬¡å…ƒå‡ºåŠ›å¯¾å¿œ: å€¤ã¨ base ã‚’å–æ¨é¸æŠ
    if isinstance(sv_local, list):
        # TreeExplainer ã®åˆ†é¡: list of arrays
        values = sv_local[0][0]
        base_val = explainer.expected_value[0]
    elif isinstance(sv_local, np.ndarray) and sv_local.ndim == 3:
        # KernelExplainer ã®å¤šå‡ºåŠ›: shape=(1, n_features, n_outputs)
        values = sv_local[0, :, 0]
        base_val = (explainer.expected_value[0]
                    if isinstance(explainer.expected_value, (list, np.ndarray))
                    else explainer.expected_value)
    else:
        # Regression or single-output
        values = sv_local[0] if (isinstance(sv_local, np.ndarray) and sv_local.ndim == 2) else sv_local
        base_val = explainer.expected_value

    # Waterfall plot
    fig, ax = plt.subplots(figsize=(8, 3 + len(values)*0.1))
    shap.plots.waterfall(
        shap.Explanation(
            values=values,
            base_values=base_val,
            data=X_test.iloc[idx]
        ),
        show=False
    )
    st.pyplot(fig)

def explain_lime(clf_model, X_train: pd.DataFrame, X_test: pd.DataFrame, task_type: str):
    """
    Display LIME explanation in Streamlit.
    """
    st.markdown("## LIME ã«ã‚ˆã‚‹èª¬æ˜")
    class_names = (clf_model.classes_.tolist() if task_type == "åˆ†é¡" else None)
    explainer = LimeTabularExplainer(
        training_data=X_train.values,
        feature_names=X_train.columns.tolist(),
        class_names=class_names,
        mode=("classification" if task_type == "åˆ†é¡" else "regression")
    )
    idx = st.slider("LIME èª¬æ˜ã®ã‚µãƒ³ãƒ—ãƒ« ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹", 0, len(X_test)-1, 0)
    exp = explainer.explain_instance(
        X_test.values[idx],
        (clf_model.predict_proba if task_type == "åˆ†é¡" else clf_model.predict)
    )
    components.html(exp.as_html(), height=350)
